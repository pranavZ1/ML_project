{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'lr': {\n",
    "        'classifier__C': [0.1, 1, 10],           # Regularization strength\n",
    "        'classifier__penalty': ['l1', 'l2'],    # Regularization type\n",
    "        'classifier__solver': ['liblinear']     # Solver that supports l1 and l2\n",
    "    },\n",
    "    'rf': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    'svc': {\n",
    "        'classifier__C': [0.1, 1, 10],          # Regularization strength\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'knn': {\n",
    "        'classifier__n_neighbors': [3, 5, 7],\n",
    "        'classifier__weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'et': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20, 30]\n",
    "    },\n",
    "    'xgb': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'classifier__max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'ada': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.5]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('lr', LogisticRegression(max_iter=5000, random_state=42)),              # Linear model\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),       # Tree-based model\n",
    "    ('svc', SVC(kernel='linear', probability=True, random_state=42)),        # SVM with linear kernel\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),                            # K-Nearest Neighbors\n",
    "    ('et', ExtraTreesClassifier(n_estimators=100, random_state=42)),         # Extra Trees Classifier\n",
    "    ('xgb', XGBClassifier( eval_metric='logloss', random_state=42)),\n",
    "    ('ada', AdaBoostClassifier(n_estimators=100, random_state=42)) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "for name, model in base_models:\n",
    "    print(f\"Tuning hyperparameters for: {name}\")\n",
    "    \n",
    "    # Create a pipeline for standardization + model\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Choose GridSearchCV or RandomizedSearchCV\n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_grids[name],\n",
    "        n_iter=20,  # Use GridSearchCV for exhaustive search, RandomizedSearchCV for faster results\n",
    "        scoring='accuracy',\n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    search.fit(X_train, Y_train)\n",
    "    \n",
    "    # Store the best model\n",
    "    best_models[name] = search.best_estimator_\n",
    "    print(f\"Best parameters for {name}: {search.best_params_}\")\n",
    "    print(f\"Best cross-validated accuracy for {name}: {search.best_score_:.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "may",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
