{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('roberta_embeddings_english_abstractive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>Judgement Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.045318</td>\n",
       "      <td>0.106291</td>\n",
       "      <td>-0.003215</td>\n",
       "      <td>-0.067849</td>\n",
       "      <td>0.027385</td>\n",
       "      <td>-0.127473</td>\n",
       "      <td>-0.029526</td>\n",
       "      <td>0.032465</td>\n",
       "      <td>0.032632</td>\n",
       "      <td>-0.086068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050516</td>\n",
       "      <td>-0.105249</td>\n",
       "      <td>-0.060616</td>\n",
       "      <td>0.014517</td>\n",
       "      <td>0.111777</td>\n",
       "      <td>0.058287</td>\n",
       "      <td>-0.074195</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.051724</td>\n",
       "      <td>0.116939</td>\n",
       "      <td>0.019695</td>\n",
       "      <td>-0.105494</td>\n",
       "      <td>0.033264</td>\n",
       "      <td>-0.070311</td>\n",
       "      <td>-0.006279</td>\n",
       "      <td>0.061977</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>-0.091103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015868</td>\n",
       "      <td>-0.088793</td>\n",
       "      <td>-0.080782</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>0.105455</td>\n",
       "      <td>0.058583</td>\n",
       "      <td>-0.040270</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>-0.013936</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.010546</td>\n",
       "      <td>0.108884</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>-0.138257</td>\n",
       "      <td>0.051355</td>\n",
       "      <td>-0.135540</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>0.051294</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>-0.042763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>-0.096850</td>\n",
       "      <td>-0.071336</td>\n",
       "      <td>-0.050518</td>\n",
       "      <td>0.096773</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>-0.091703</td>\n",
       "      <td>-0.011808</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.054942</td>\n",
       "      <td>0.087816</td>\n",
       "      <td>0.019472</td>\n",
       "      <td>-0.118021</td>\n",
       "      <td>0.059199</td>\n",
       "      <td>-0.082324</td>\n",
       "      <td>-0.024870</td>\n",
       "      <td>0.060929</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>-0.098716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011953</td>\n",
       "      <td>-0.098715</td>\n",
       "      <td>-0.092882</td>\n",
       "      <td>-0.004579</td>\n",
       "      <td>0.122452</td>\n",
       "      <td>-0.007312</td>\n",
       "      <td>-0.053264</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.026756</td>\n",
       "      <td>0.077807</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>-0.094653</td>\n",
       "      <td>0.057685</td>\n",
       "      <td>-0.071129</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>0.097987</td>\n",
       "      <td>0.053599</td>\n",
       "      <td>-0.065829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013227</td>\n",
       "      <td>-0.050602</td>\n",
       "      <td>-0.054803</td>\n",
       "      <td>-0.005757</td>\n",
       "      <td>0.072578</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>-0.040133</td>\n",
       "      <td>-0.029626</td>\n",
       "      <td>0.037816</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-0.052280</td>\n",
       "      <td>0.063353</td>\n",
       "      <td>-0.029092</td>\n",
       "      <td>-0.112168</td>\n",
       "      <td>0.026026</td>\n",
       "      <td>-0.086139</td>\n",
       "      <td>-0.025001</td>\n",
       "      <td>0.079336</td>\n",
       "      <td>0.038220</td>\n",
       "      <td>-0.089051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>-0.049991</td>\n",
       "      <td>-0.083095</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>0.136884</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>-0.103072</td>\n",
       "      <td>-0.027759</td>\n",
       "      <td>-0.016507</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>-0.040454</td>\n",
       "      <td>0.080203</td>\n",
       "      <td>-0.015394</td>\n",
       "      <td>-0.101792</td>\n",
       "      <td>0.036181</td>\n",
       "      <td>-0.041597</td>\n",
       "      <td>0.007757</td>\n",
       "      <td>0.047865</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>-0.091039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021505</td>\n",
       "      <td>-0.032031</td>\n",
       "      <td>-0.064167</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>0.122567</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>-0.076298</td>\n",
       "      <td>-0.009738</td>\n",
       "      <td>-0.027242</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-0.067318</td>\n",
       "      <td>0.111115</td>\n",
       "      <td>-0.009719</td>\n",
       "      <td>-0.082606</td>\n",
       "      <td>0.054640</td>\n",
       "      <td>-0.103232</td>\n",
       "      <td>-0.002115</td>\n",
       "      <td>0.021089</td>\n",
       "      <td>0.034756</td>\n",
       "      <td>-0.104129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019006</td>\n",
       "      <td>-0.062294</td>\n",
       "      <td>-0.049686</td>\n",
       "      <td>0.042695</td>\n",
       "      <td>0.105910</td>\n",
       "      <td>0.013915</td>\n",
       "      <td>-0.079819</td>\n",
       "      <td>-0.008745</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>-0.064715</td>\n",
       "      <td>0.088847</td>\n",
       "      <td>-0.013383</td>\n",
       "      <td>-0.087596</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>-0.089861</td>\n",
       "      <td>-0.038170</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>-0.015348</td>\n",
       "      <td>-0.094655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>-0.061830</td>\n",
       "      <td>-0.096422</td>\n",
       "      <td>-0.021497</td>\n",
       "      <td>0.139260</td>\n",
       "      <td>0.059158</td>\n",
       "      <td>-0.117424</td>\n",
       "      <td>-0.034884</td>\n",
       "      <td>-0.042829</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-0.054698</td>\n",
       "      <td>0.137445</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>-0.082863</td>\n",
       "      <td>0.036587</td>\n",
       "      <td>-0.051519</td>\n",
       "      <td>-0.023912</td>\n",
       "      <td>0.041945</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>-0.078507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009144</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>-0.056368</td>\n",
       "      <td>0.013269</td>\n",
       "      <td>0.106635</td>\n",
       "      <td>0.019491</td>\n",
       "      <td>-0.059023</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>-0.039424</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.045318  0.106291 -0.003215 -0.067849  0.027385 -0.127473 -0.029526   \n",
       "1   -0.051724  0.116939  0.019695 -0.105494  0.033264 -0.070311 -0.006279   \n",
       "2   -0.010546  0.108884  0.001479 -0.138257  0.051355 -0.135540  0.008098   \n",
       "3   -0.054942  0.087816  0.019472 -0.118021  0.059199 -0.082324 -0.024870   \n",
       "4   -0.026756  0.077807 -0.000185 -0.094653  0.057685 -0.071129 -0.000685   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "595 -0.052280  0.063353 -0.029092 -0.112168  0.026026 -0.086139 -0.025001   \n",
       "596 -0.040454  0.080203 -0.015394 -0.101792  0.036181 -0.041597  0.007757   \n",
       "597 -0.067318  0.111115 -0.009719 -0.082606  0.054640 -0.103232 -0.002115   \n",
       "598 -0.064715  0.088847 -0.013383 -0.087596  0.054902 -0.089861 -0.038170   \n",
       "599 -0.054698  0.137445  0.013111 -0.082863  0.036587 -0.051519 -0.023912   \n",
       "\n",
       "            7         8         9  ...       759       760       761  \\\n",
       "0    0.032465  0.032632 -0.086068  ... -0.050516 -0.105249 -0.060616   \n",
       "1    0.061977  0.007398 -0.091103  ... -0.015868 -0.088793 -0.080782   \n",
       "2    0.051294  0.010994 -0.042763  ...  0.014642 -0.096850 -0.071336   \n",
       "3    0.060929  0.012410 -0.098716  ... -0.011953 -0.098715 -0.092882   \n",
       "4    0.097987  0.053599 -0.065829  ... -0.013227 -0.050602 -0.054803   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "595  0.079336  0.038220 -0.089051  ...  0.003848 -0.049991 -0.083095   \n",
       "596  0.047865  0.008642 -0.091039  ...  0.021505 -0.032031 -0.064167   \n",
       "597  0.021089  0.034756 -0.104129  ...  0.019006 -0.062294 -0.049686   \n",
       "598  0.046950 -0.015348 -0.094655  ...  0.003160 -0.061830 -0.096422   \n",
       "599  0.041945  0.013002 -0.078507  ...  0.009144 -0.001875 -0.056368   \n",
       "\n",
       "          762       763       764       765       766       767  \\\n",
       "0    0.014517  0.111777  0.058287 -0.074195  0.009236  0.020355   \n",
       "1    0.007715  0.105455  0.058583 -0.040270  0.008042 -0.013936   \n",
       "2   -0.050518  0.096773  0.024355 -0.091703 -0.011808  0.005190   \n",
       "3   -0.004579  0.122452 -0.007312 -0.053264 -0.000205  0.005530   \n",
       "4   -0.005757  0.072578  0.028736 -0.040133 -0.029626  0.037816   \n",
       "..        ...       ...       ...       ...       ...       ...   \n",
       "595  0.011732  0.136884  0.000406 -0.103072 -0.027759 -0.016507   \n",
       "596  0.021279  0.122567  0.013715 -0.076298 -0.009738 -0.027242   \n",
       "597  0.042695  0.105910  0.013915 -0.079819 -0.008745  0.007531   \n",
       "598 -0.021497  0.139260  0.059158 -0.117424 -0.034884 -0.042829   \n",
       "599  0.013269  0.106635  0.019491 -0.059023  0.004726 -0.039424   \n",
       "\n",
       "     Judgement Status  \n",
       "0                   1  \n",
       "1                   2  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   3  \n",
       "..                ...  \n",
       "595                 3  \n",
       "596                 2  \n",
       "597                 2  \n",
       "598                 3  \n",
       "599                 3  \n",
       "\n",
       "[600 rows x 769 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target (last column)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models to test\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=5000, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Support Vector Machine\": SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=50, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "}\n",
    "\n",
    "# Evaluate each model using cross-validation\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('model', model)])  # Include scaling in pipeline\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    results.append((name, np.mean(scores), np.std(scores)))\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Mean Accuracy\", \"Std Deviation\"])\n",
    "print(results_df.sort_values(by=\"Mean Accuracy\", ascending=False))\n",
    "\n",
    "# Optional: Train and test the best model\n",
    "best_model_name, best_model = max(models.items(), key=lambda x: cross_val_score(Pipeline([('scaler', StandardScaler()), ('model', x[1])]), X_train, y_train, cv=5, scoring='accuracy').mean())\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best Model: {best_model_name} with Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "may",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
